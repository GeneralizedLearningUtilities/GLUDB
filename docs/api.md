
# Package gludb

glubdb - A simple database wrapper

# Package gludb.backends

glubdb.backends - implementation of actual db backends

## module gludb.backends.dynamodb

(in pkg gludb.backends)

gludb.backends.dynamodb - backend dynamodb database module

### class Backend

Full qualified name: gludb.backends.dynamodb.Backend

None
Class members that aren't methods

 + \_\_init\_\_
 + ensure\_table
 + find\_all
 + find\_by\_index
 + find\_one
 + get\_class\_table
 + save
 + table\_schema\_call




### class DynamoMappings

Full qualified name: gludb.backends.dynamodb.DynamoMappings

DynamoDB has some opinions about what you can store or query in an
attribute. We're going to use mappings to fix that.

#### method *map\_index\_val*

> Argument specification:
> (index\_val)

Xform index_val so that it can be stored/queried


#### method *unmap\_stored\_val*

> Argument specification:
> (stored\_val)

Inverse of index_val_mapping. Note that we currently don't use it
because we don't actually read back index values (since they are
generated by Python functions)

Class members that aren't methods

 + EMPTY\_STR\_VAL
 + NONE\_VAL
 + \_\_init\_\_
















### function *delete_table*

Mainly for testing


### function *get_conn*

Return a connection to DynamoDB (and handle local/debug
possibilities)


### function *gsi_name*

Standardize how we create a GSI name for DynamoDB from the given index
name from the class


### function *uuid*

Return a decent UUID as a string



## module gludb.backends.gcd

(in pkg gludb.backends)

gludb.backends.gcd - backend Google Cloud Datastore module

### class Backend

Full qualified name: gludb.backends.gcd.Backend

None
Class members that aren't methods

 + \_\_init\_\_
 + ensure\_table
 + find\_all
 + find\_by\_index
 + find\_one
 + save


### class DatastoreTransaction

Full qualified name: gludb.backends.gcd.DatastoreTransaction

None
Class members that aren't methods

 + \_\_init\_\_
 + get\_commit\_req
 + get\_upsert


### function *delete_table*

Mainly for testing


### function *extract_entity*

None


### function *make_key*

None


### function *read_by_indexes*

None


### function *read_rec*

None


### function *uuid*

Return a decent UUID as a string


### function *write_rec*

None



## module gludb.backends.mongodb

(in pkg gludb.backends)

MongoDB backend

### class Backend

Full qualified name: gludb.backends.mongodb.Backend

None
Class members that aren't methods

 + \_\_init\_\_
 + ensure\_table
 + find\_all
 + find\_by\_index
 + find\_one
 + get\_collection
 + save






### function *delete_collection*

Almost exclusively for testing


### function *uuid*

Return a decent UUID as a string



## module gludb.backends.sqlite

(in pkg gludb.backends)

gludb.backends.sqlite - backend sqlite database module

### class Backend

Full qualified name: gludb.backends.sqlite.Backend

None
Class members that aren't methods

 + \_\_init\_\_
 + ensure\_table
 + find\_all
 + find\_by\_index
 + find\_one
 + save


### function *uuid*

Return a decent UUID as a string




## module gludb.backup

(in pkg gludb)

Supply backup functionality for gludb. Note that we mainly provide a way for
users to create a small script that backs up their data to S3. We are assuming
that the S3 bucket used will be configured for archival (either deletion or
archival to Glacier)

### class Backup

Full qualified name: gludb.backup.Backup

None
Class members that aren't methods

 + \_\_init\_\_
 + add\_class
 + add\_package
 + aws\_access\_key
 + aws\_secret\_key
 + backup\_log
 + bucketname
 + ensure\_table
 + find\_all
 + find\_by\_index
 + find\_one
 + from\_data
 + get\_id
 + get\_table\_name
 + get\_versioning
 + index\_names
 + indexes
 + log
 + name
 + run\_backup
 + save
 + set\_id
 + setup
 + timestamp
 + to\_data


### function *DBObject*

Classes annotated with DBObject gain persistence methods.






### function *NamedTemporaryFile*

Create and return a temporary file.
Arguments:
'prefix', 'suffix', 'dir' -- as for mkstemp.
'mode' -- the mode argument to os.fdopen (default "w+b").
'bufsize' -- the buffer size argument to os.fdopen (default -1).
'delete' -- whether the file is deleted on close (default True).
The file is created as mkstemp() would do it.

Returns an object with a file-like interface; the name of the file
is accessible as file.name.  The file will be automatically deleted
when it is closed unless the 'delete' argument is set to False.








### function *backup_name*

None


### function *get_mapping*

Return a database config object for the given class


### function *getmembers*

Return all members of an object as (name, value) pairs sorted by name.
Optionally, only return members that satisfy a given predicate.


### function *getmro*

Return tuple of base classes (including cls) in method resolution order.


### function *import_module*

Import a module.

The 'package' argument is required when performing a relative import. It
specifies the package to use as the anchor point from which to resolve the
relative import to an absolute import.


### function *is_backup_class*

None


### function *isclass*

Return true if the object is a class.

Class objects provide these attributes:
    __doc__         documentation string
    __module__      name of module in which this class was defined


### function *now_field*

Return a string we use for storing our date time values


### function *strip_line*

None


### function *write_line*

None



## module gludb.config

(in pkg gludb)

Provide gludb configuration. This consists mainly of a mapping from Storable
classes to a database configuration. It also includes a default mapping for
classes not specifically mapped to a database.

We check for a mapping for a class in MRO (Method Resolution Order). Suppose
a class Busy derives from the three classes X, Y, and Z - all of which derive
from class Base:

    class Base(object):
        pass

    class X(Base):
        pass
    class Y(Base):
        pass
    class Z(Base):
        pass

    class Busy(X, Y, Z):
        pass

Then a check for mapping would first checking for class Busy, then (in order)
classes X, Y, Z, Base, and object. If this is the first time you've seen
multiple inheritance, you'll note that the order of Busy's super classes is
important. This is how Python resolves method calls (we didn't just make this
up). In fact, we depend on the results of the standard library call
`inspect.getmro`.

If none of the classes mentioned have a mapping, then the default mapping will
be used. If there is no default mapping, then the class can't be mapped to a
database instance and an error will be thrown.

Astute readers will note that you could map the class `object` to a database
as a kind of default mapping. We generally don't recommend this, because it
would work *sort of*. Some notes:

* Recall that we support Python 2 and 3. In Python 3.4, classes declared
  without a base class get `object` as a base class automatically. In Python
  2.7 they just don't have a base class. That means that using an `object`
  DB mapping won't work as a default in every case.
* We always check for the default database mapping last, so mapping to object
  would be the last thing checked before the actual default.

### class Database

Full qualified name: gludb.config.Database

Configuration class representing a database instance supported by one
of our backends
Class members that aren't methods

 + \_\_init\_\_
 + ensure\_table
 + find\_all
 + find\_by\_index
 + find\_one
 + save


### function *class_database*

Map a class (for which we assume issubclass(cls, Storable)==True) to
a database configuration


### function *clear_database_config*

Reset all mappings to default state. Note that any in-memory databases
will be lost


### function *default_database*

Set the default database configuration used for classes without a
specific mapping


### function *get_mapping*

Return a database config object for the given class


### function *getmro*

Return tuple of base classes (including cls) in method resolution order.


### function *import_module*

Import a module.

The 'package' argument is required when performing a relative import. It
specifies the package to use as the anchor point from which to resolve the
relative import to an absolute import.



## module gludb.data

(in pkg gludb)

gludb.data

The "core" functionality. If you're unsure what to use, you should look into
gludb.simple. This module is for those needing advanced functionality or
customization



### function *DatabaseEnabled*

Classes annotated with DatabaseEnabled gain persistence methods. All
this really does is add some functions that forward to the mapped database
class


### class Storable

Full qualified name: gludb.data.Storable

Our abstract base class that marks subclasses as persistable and
storable. Note that the DBObject annotation in gludb.simple registers
all annotated classes as 'virtual base classes' of Storage so that you
can test them with isinstance(obj, Storable)
Class members that aren't methods

 + ORIG\_VER\_FIELD\_NAME
 + \_\_init\_\_
 + from\_data
 + get\_id
 + get\_table\_name
 + get\_versioning
 + index\_names
 + indexes
 + set\_id
 + to\_data


### function *abstractmethod*

A decorator indicating abstract methods.

Requires that the metaclass is ABCMeta or derived from it.  A
class that has a metaclass derived from ABCMeta cannot be
instantiated unless all of its abstract methods are overridden.
The abstract methods can be called using any of the normal
'super' call mechanisms.

Usage:

    class C:
        __metaclass__ = ABCMeta
        @abstractmethod
        def my_abstract_method(self, ...):
            ...


### function *get_mapping*

Return a database config object for the given class


### function *orig_version*

Return the original version of an object (defined as what was read from
the database before any user edits). If there isn't a previous version (for
instance, newly created objects don't have a previous version), then None
is returned. Mainly useful for testing



## module gludb.simple

(in pkg gludb)

gludb.simple

Provides the simplest possible interface to our functionality.

We provide a simple annotation to create classes with fields (with optional
default values), parameterized constructors, persistence, and data operations.
You are free to derive from any object you wish. See gludb.data if you need
custom or more advanced functionality.

    @DBObject
    class Demo(object):
        some_field = Field()
        my_number = Field(default=42)

    d = Demo(some_field='foo', my_number=3.14)
    print(d.to_data())  # Prints a JSON representation
    d1 = Demo.from_data(d.to_data())  # Clone using persistence functions
    d.save()  # Save to database
    for obj in Demo.find_all():  # Print json rep of all objects in DB
        print(obj.to_data())

Also note that currently we aren't supporting nested DBObject objects.
HOWEVER, we make no restrictions on a field being a JSON-compatible Python
type. We make it possible to supply a decent default value by allowing a
function to be specified as a default value - it will be called when a default
value is needed. For example:

    @DBObject
    class Complicated(object):
        name = Field(default='')
        complex_data = Field(default=dict)

    c = Complicate(name)
    c.complex_data['a'] = 123
    c.complex_data['b'] = 456

IMPORTANT: you should *NOT* just use a default object like this:
`Field(default={})`. Modifications made to the default object will become the
NEW default for other classes. See
[here](http://effbot.org/zone/default-values.htm). However, you may supply
a function that will be called to retreive a default value. In this example
you should use `Field(default=dict)`.

### function *DBObject*

Classes annotated with DBObject gain persistence methods.


### function *DatabaseEnabled*

Classes annotated with DatabaseEnabled gain persistence methods. All
this really does is add some functions that forward to the mapped database
class


### class Field

Full qualified name: gludb.simple.Field

Support for class-level field declaration.
    
Class members that aren't methods

 + \_\_init\_\_
 + get\_default\_val


### function *Index*

Marks instance methods of a DBObject-decorated class as being used for
indexing. The function name is used as the index name, and the return
value is used as the index value.

Note that callables are call recursively so in theory you can return
a function which will be called to get the index value






### function *append_diff_hist*

Given a diff as generated by record_diff, append a diff record to the
list of diff_hist records.


### function *now_field*

Return a string we use for storing our date time values


### function *orig_version*

Return the original version of an object (defined as what was read from
the database before any user edits). If there isn't a previous version (for
instance, newly created objects don't have a previous version), then None
is returned. Mainly useful for testing


### function *record_diff*

Return a JSON-compatible structure capable turn the `new` record back
into the `old` record. The parameters must be structures compatible with
json.dumps *or* strings compatible with json.loads. Note that by design,
`old == record_patch(new, record_diff(old, new))`



## module gludb.utils

(in pkg gludb)

Central place for misc utilities

### function *now_field*

Return a string we use for storing our date time values


### function *uuid*

Return a decent UUID as a string


### function *uuid4*

Generate a random UUID.



## module gludb.versioning

(in pkg gludb)

versioning.py

GLUDB versioning implementation

### class VersioningTypes

Full qualified name: gludb.versioning.VersioningTypes

None
Class members that aren't methods

 + DELTA\_HISTORY
 + NONE
 + \_\_init\_\_


### function *append_diff_hist*

Given a diff as generated by record_diff, append a diff record to the
list of diff_hist records.


### function *parse_diff_hist*

Given a diff_hist as created, appended by append_diff_hist, yield the
versions of the object start with curr_obj and working backwards in time.
Each instance yielded is of the form (obj, date-string) where obj is the
JSON-compatible version of the object created by applying a diff in the
diff history and date-string is a string representing the date/time that
the diff was taken


### function *record_diff*

Return a JSON-compatible structure capable turn the `new` record back
into the `old` record. The parameters must be structures compatible with
json.dumps *or* strings compatible with json.loads. Note that by design,
`old == record_patch(new, record_diff(old, new))`


### function *record_patch*

Return the JSON-compatible structure that results from applying the
changes in `diff` to the record `rec`. The parameters must be structures
compatible with json.dumps *or* strings compatible with json.loads. Note
that by design, `old == record_patch(new, record_diff(old, new))`



